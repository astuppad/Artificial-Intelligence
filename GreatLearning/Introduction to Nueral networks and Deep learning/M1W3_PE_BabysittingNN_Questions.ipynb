{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "    \n",
    "In this notebook, we will build a neural network to classifiy the image based on the object present in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info:\n",
    "    \n",
    "MNIST database of handwritten digits\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "\n",
    "Source: https://www.kaggle.com/warisali2/mnist-database-of-handwritten-digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced techniques for training neural networks:\n",
    "    \n",
    "Weight Initialization\n",
    "\n",
    "Nonlinearity (different Activation functions)\n",
    "\n",
    "Optimizers(different optimizers)\n",
    "\n",
    "Batch Normalization\n",
    "\n",
    "Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Libraries and dataset and do experimentation on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist    \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive MLP model without any alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=50, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(units=50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n60000/60000 [==============================] - 21s 354us/step - loss: 1.7961 - accuracy: 0.3390\nEpoch 2/10\n60000/60000 [==============================] - 20s 341us/step - loss: 1.5348 - accuracy: 0.4386\nEpoch 3/10\n60000/60000 [==============================] - 20s 342us/step - loss: 1.4604 - accuracy: 0.4743\nEpoch 4/10\n60000/60000 [==============================] - 22s 361us/step - loss: 1.4849 - accuracy: 0.4511\nEpoch 5/10\n60000/60000 [==============================] - 25s 414us/step - loss: 1.4428 - accuracy: 0.4764\nEpoch 6/10\n60000/60000 [==============================] - 37s 609us/step - loss: 1.2658 - accuracy: 0.5482\nEpoch 7/10\n60000/60000 [==============================] - 31s 515us/step - loss: 1.1654 - accuracy: 0.5764\nEpoch 8/10\n60000/60000 [==============================] - 27s 454us/step - loss: 1.0977 - accuracy: 0.6096\nEpoch 9/10\n60000/60000 [==============================] - 26s 429us/step - loss: 1.1536 - accuracy: 0.5870\nEpoch 10/10\n60000/60000 [==============================] - 32s 527us/step - loss: 1.0452 - accuracy: 0.6369\n"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=2, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 0s 16us/step\nTest accuracy:  0.6262999773025513\n"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we will train Neural network using below techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Weight Initialization\n",
    "\n",
    "Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem \n",
    "up to some degree\n",
    "\n",
    "Ref: https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(50, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.sgd(learning_rate=0.001)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n60000/60000 [==============================] - 1s 9us/step - loss: 2.5300 - accuracy: 0.0986\nEpoch 2/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.4320 - accuracy: 0.1033\nEpoch 3/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.3776 - accuracy: 0.1146\nEpoch 4/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.3429 - accuracy: 0.1075\nEpoch 5/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.3210 - accuracy: 0.1106\nEpoch 6/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.3084 - accuracy: 0.1135\nEpoch 7/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.3018 - accuracy: 0.1128\nEpoch 8/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2985 - accuracy: 0.1129\nEpoch 9/100\n60000/60000 [==============================] - 1s 8us/step - loss: 2.2968 - accuracy: 0.1125\nEpoch 10/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2957 - accuracy: 0.1125\nEpoch 11/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2950 - accuracy: 0.1124\nEpoch 12/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2943 - accuracy: 0.1124\nEpoch 13/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2937 - accuracy: 0.1124\nEpoch 14/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2930 - accuracy: 0.1124\nEpoch 15/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2924 - accuracy: 0.1124\nEpoch 16/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2918 - accuracy: 0.1124\nEpoch 17/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2912 - accuracy: 0.1125\nEpoch 18/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2907 - accuracy: 0.1125\nEpoch 19/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2901 - accuracy: 0.1125\nEpoch 20/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2895 - accuracy: 0.1125\nEpoch 21/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2889 - accuracy: 0.1125\nEpoch 22/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2883 - accuracy: 0.1125\nEpoch 23/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2877 - accuracy: 0.1125\nEpoch 24/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2871 - accuracy: 0.1131\nEpoch 25/100\n60000/60000 [==============================] - 1s 9us/step - loss: 2.2865 - accuracy: 0.1125\nEpoch 26/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2859 - accuracy: 0.1125\nEpoch 27/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2853 - accuracy: 0.1126\nEpoch 28/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2846 - accuracy: 0.1131\nEpoch 29/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2840 - accuracy: 0.1129\nEpoch 30/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2834 - accuracy: 0.1128\nEpoch 31/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2827 - accuracy: 0.1129\nEpoch 32/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2821 - accuracy: 0.1140\nEpoch 33/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2814 - accuracy: 0.1138\nEpoch 34/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2808 - accuracy: 0.1128\nEpoch 35/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2801 - accuracy: 0.1144\nEpoch 36/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2794 - accuracy: 0.1147\nEpoch 37/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2787 - accuracy: 0.1136\nEpoch 38/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2780 - accuracy: 0.1147\nEpoch 39/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2773 - accuracy: 0.1148\nEpoch 40/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2766 - accuracy: 0.1172\nEpoch 41/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2759 - accuracy: 0.1159\nEpoch 42/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2751 - accuracy: 0.1157\nEpoch 43/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2743 - accuracy: 0.1178\nEpoch 44/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2736 - accuracy: 0.1171\nEpoch 45/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2728 - accuracy: 0.1188\nEpoch 46/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2720 - accuracy: 0.1218\nEpoch 47/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2712 - accuracy: 0.1219\nEpoch 48/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2704 - accuracy: 0.1216\nEpoch 49/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2696 - accuracy: 0.1230\nEpoch 50/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2688 - accuracy: 0.1235\nEpoch 51/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2680 - accuracy: 0.1287\nEpoch 52/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2672 - accuracy: 0.1317\nEpoch 53/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2664 - accuracy: 0.1390\nEpoch 54/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2656 - accuracy: 0.1360\nEpoch 55/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2647 - accuracy: 0.1414\nEpoch 56/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2638 - accuracy: 0.1375\nEpoch 57/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2629 - accuracy: 0.1434\nEpoch 58/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2621 - accuracy: 0.1483\nEpoch 59/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2612 - accuracy: 0.1514\nEpoch 60/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2603 - accuracy: 0.1685\nEpoch 61/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2593 - accuracy: 0.1697\nEpoch 62/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2584 - accuracy: 0.1707\nEpoch 63/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2575 - accuracy: 0.1716\nEpoch 64/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2565 - accuracy: 0.1804\nEpoch 65/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2555 - accuracy: 0.1988\nEpoch 66/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2545 - accuracy: 0.2025\nEpoch 67/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2535 - accuracy: 0.1988\nEpoch 68/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2525 - accuracy: 0.2070\nEpoch 69/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2515 - accuracy: 0.2264\nEpoch 70/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2505 - accuracy: 0.2112\nEpoch 71/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2494 - accuracy: 0.2242\nEpoch 72/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2483 - accuracy: 0.2376\nEpoch 73/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2472 - accuracy: 0.2423\nEpoch 74/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2461 - accuracy: 0.2576\nEpoch 75/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2450 - accuracy: 0.2583\nEpoch 76/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2438 - accuracy: 0.2615\nEpoch 77/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2427 - accuracy: 0.2796\nEpoch 78/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2415 - accuracy: 0.2892\nEpoch 79/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2403 - accuracy: 0.2994\nEpoch 80/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2390 - accuracy: 0.2873\nEpoch 81/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2378 - accuracy: 0.3031\nEpoch 82/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2365 - accuracy: 0.3096\nEpoch 83/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2352 - accuracy: 0.3135\nEpoch 84/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2338 - accuracy: 0.3194\nEpoch 85/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2325 - accuracy: 0.3249\nEpoch 86/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2311 - accuracy: 0.3325\nEpoch 87/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2296 - accuracy: 0.3335\nEpoch 88/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2282 - accuracy: 0.3406\nEpoch 89/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2267 - accuracy: 0.3458\nEpoch 90/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2252 - accuracy: 0.3498\nEpoch 91/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2236 - accuracy: 0.3614\nEpoch 92/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2221 - accuracy: 0.3587\nEpoch 93/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2204 - accuracy: 0.3693\nEpoch 94/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2188 - accuracy: 0.3748\nEpoch 95/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2171 - accuracy: 0.3710\nEpoch 96/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2154 - accuracy: 0.3813\nEpoch 97/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2136 - accuracy: 0.3838\nEpoch 98/100\n60000/60000 [==============================] - 0s 7us/step - loss: 2.2118 - accuracy: 0.3817\nEpoch 99/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2099 - accuracy: 0.3905\nEpoch 100/100\n60000/60000 [==============================] - 0s 8us/step - loss: 2.2080 - accuracy: 0.3902\n"
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size=200, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 0s 17us/step\nTest Accuracy:  0.39590001106262207\n"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Nonlinearity (Activation function)\n",
    "\n",
    "Sigmoid functions suffer from gradient vanishing problem, making training slower\n",
    "\n",
    "There are many choices apart from sigmoid and tanh; try many of them!\n",
    "\n",
    "'relu' (rectified linear unit) is one of the most popular ones\n",
    "\n",
    "Ref: https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(50, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.sgd(learning_rate=0.001)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n60000/60000 [==============================] - 2s 31us/step - loss: 0.9393 - accuracy: 0.7703\nEpoch 2/10\n60000/60000 [==============================] - 2s 27us/step - loss: 0.3831 - accuracy: 0.8897\nEpoch 3/10\n60000/60000 [==============================] - 2s 26us/step - loss: 0.2962 - accuracy: 0.9135\nEpoch 4/10\n60000/60000 [==============================] - 2s 26us/step - loss: 0.2518 - accuracy: 0.9257\nEpoch 5/10\n60000/60000 [==============================] - 2s 27us/step - loss: 0.2237 - accuracy: 0.9334\nEpoch 6/10\n60000/60000 [==============================] - 2s 29us/step - loss: 0.2030 - accuracy: 0.9395\nEpoch 7/10\n60000/60000 [==============================] - 2s 28us/step - loss: 0.1887 - accuracy: 0.9438\nEpoch 8/10\n60000/60000 [==============================] - 2s 27us/step - loss: 0.1775 - accuracy: 0.9471\nEpoch 9/10\n60000/60000 [==============================] - 2s 27us/step - loss: 0.1670 - accuracy: 0.9506\nEpoch 10/10\n60000/60000 [==============================] - 2s 26us/step - loss: 0.1594 - accuracy: 0.9537\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x15567a910>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train,y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 0s 14us/step\nTest Accuracy:  0.9435999989509583\n"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Batch Normalization\n",
    "\n",
    "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n",
    "\n",
    "Normalize each mini-batch before nonlinearity\n",
    "\n",
    "Ref: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n60000/60000 [==============================] - 4s 69us/step - loss: 1.5279 - accuracy: 0.5364\nEpoch 2/20\n60000/60000 [==============================] - 3s 57us/step - loss: 0.8158 - accuracy: 0.7981\nEpoch 3/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.5948 - accuracy: 0.8479\nEpoch 4/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.4915 - accuracy: 0.8688\nEpoch 5/20\n60000/60000 [==============================] - 3s 53us/step - loss: 0.4329 - accuracy: 0.8821\nEpoch 6/20\n60000/60000 [==============================] - 3s 56us/step - loss: 0.3881 - accuracy: 0.8929\nEpoch 7/20\n60000/60000 [==============================] - 3s 54us/step - loss: 0.3627 - accuracy: 0.8991\nEpoch 8/20\n60000/60000 [==============================] - 3s 54us/step - loss: 0.3386 - accuracy: 0.9046\nEpoch 9/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.3164 - accuracy: 0.9096\nEpoch 10/20\n60000/60000 [==============================] - 3s 49us/step - loss: 0.3036 - accuracy: 0.9139\nEpoch 11/20\n60000/60000 [==============================] - 3s 49us/step - loss: 0.2891 - accuracy: 0.9189\nEpoch 12/20\n60000/60000 [==============================] - 3s 52us/step - loss: 0.2801 - accuracy: 0.9202\nEpoch 13/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.2648 - accuracy: 0.9237\nEpoch 14/20\n60000/60000 [==============================] - 3s 49us/step - loss: 0.2570 - accuracy: 0.9251\nEpoch 15/20\n60000/60000 [==============================] - 3s 51us/step - loss: 0.2484 - accuracy: 0.9280\nEpoch 16/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.2423 - accuracy: 0.9301\nEpoch 17/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.2343 - accuracy: 0.9327\nEpoch 18/20\n60000/60000 [==============================] - 3s 50us/step - loss: 0.2259 - accuracy: 0.9338\nEpoch 19/20\n60000/60000 [==============================] - 3s 48us/step - loss: 0.2186 - accuracy: 0.9363\nEpoch 20/20\n60000/60000 [==============================] - 3s 49us/step - loss: 0.2130 - accuracy: 0.9377\n"
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization layer is usually inserted after dense/convolution and before nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 0s 27us/step\nTest Accuracy:  0.9545999765396118\n"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))    \n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))   \n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n60000/60000 [==============================] - 6s 102us/step - loss: 0.7165 - accuracy: 0.7837\nEpoch 2/10\n60000/60000 [==============================] - 5s 91us/step - loss: 0.4166 - accuracy: 0.8815\nEpoch 3/10\n60000/60000 [==============================] - 5s 84us/step - loss: 0.3525 - accuracy: 0.8992\nEpoch 4/10\n60000/60000 [==============================] - 6s 92us/step - loss: 0.3146 - accuracy: 0.9105\nEpoch 5/10\n60000/60000 [==============================] - 5s 90us/step - loss: 0.2910 - accuracy: 0.9172\nEpoch 6/10\n60000/60000 [==============================] - 5s 87us/step - loss: 0.2781 - accuracy: 0.9201\nEpoch 7/10\n60000/60000 [==============================] - 5s 85us/step - loss: 0.2611 - accuracy: 0.9262\nEpoch 8/10\n60000/60000 [==============================] - 6s 94us/step - loss: 0.2560 - accuracy: 0.9277\nEpoch 9/10\n60000/60000 [==============================] - 5s 90us/step - loss: 0.2445 - accuracy: 0.9299\nEpoch 10/10\n60000/60000 [==============================] - 5s 82us/step - loss: 0.2359 - accuracy: 0.9310\n"
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 0s 32us/step\nTest Accuracy:  0.9689000248908997\n"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}